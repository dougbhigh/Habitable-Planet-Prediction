{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "#  RUT-SOM-DATA-PT-06-2020-U-C                                                    Douglas High #\n",
    "#   Machine-Learning-Challenge                                                November 7, 2020 #\n",
    "#         > model0_compare.ipynb                                                               #\n",
    "#                                                                                              #\n",
    "#  > Part1: 00.UI-Update/Install to 50-Compare-df                                              #\n",
    "#     - setup (read in data, split & scale, create compare_df to list each methods score).     #\n",
    "#                                                                                              #\n",
    "#  > Part2: 100.00-LinearRegression-no-scale to 190-Write/Sort                                 #\n",
    "#     - run 27 model variations (9 models-no scaling, standard(ss) and minmax(mm)).            #\n",
    "#     - append their train, test, and avg score to compare_df.                                 #\n",
    "#     - save df to csv, sort and display to see best performing models.                        #\n",
    "#                                                                                              #\n",
    "#  > Part3: 200-DecisionTree(ss)features to 220-RandomForest(00)feature                        #\n",
    "#     - list and plot feature importance for top three performing variations.                  #\n",
    "#                                                                                              #\n",
    "#  > Part4: 300-DecisionTree(ss)feature-selection to 320-RandomForest(00)-feature-selection.   #\n",
    "#     - feature selections. remove features of top 3 performers based on Part3 results.        #\n",
    "#     - resplit & rescale data. compare train/test/avg scores with full features models.       #\n",
    "#                                                                                              #\n",
    "#  > Part5: 400-ModelParameters  to 460-RandomForest-GridResult                                #  \n",
    "#     - classifiers of the top three models are plotted and sorted in a df and displayed.      #\n",
    "#     - GridSearch is done for each of the three to find best variation of each model.         #\n",
    "#     - best parameters and classification report printed for each along with a comparison     #\n",
    "#       of each one's original test score, after features removed, and after hypertuned.       #\n",
    "################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "#00.UI     Update/Install                                                   #\n",
    "#    a- install/check for update sklearn (to prevent version mismatches).   #\n",
    "#    b- install joblib - used to save model (uncomment to install).         #\n",
    "#       *** Restart Kernal after joblib install ***                         #\n",
    "#############################################################################\n",
    "\n",
    "#a\n",
    "!pip install sklearn --upgrade\n",
    "\n",
    "#b\n",
    "# !pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "#00   I/O                 #\n",
    "#   - import libraries.   #\n",
    "#   - associate file.     #\n",
    "###########################\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "data_in = \"../data_in/exoplanet_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "#10     Read and remove                                                      #\n",
    "#   - read data into df.                                                     #\n",
    "#   - drop null columns if all values are null.                              #\n",
    "#   - drop null rows.                                                        #\n",
    "#   - keep only records with a known value (confirmed or false positive).    #\n",
    "##############################################################################\n",
    "\n",
    "df = pd.read_csv(data_in)\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "df = df.dropna()\n",
    "\n",
    "known_df = df[df[\"koi_disposition\"] != \"CANDIDATE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "#20     Set Features                               #\n",
    "#   a- select all columns to use as features       #\n",
    "#    - disposition is the dependent variable.      #\n",
    "#   b- convert disposition to two binary columns   #\n",
    "#      and delete the second one.                  #\n",
    "####################################################\n",
    "\n",
    "#a\n",
    "X = known_df.drop(\"koi_disposition\", axis=1)\n",
    "y = known_df[\"koi_disposition\"]\n",
    "\n",
    "#b\n",
    "y = pd.get_dummies(y)\n",
    "y = y.drop(\"FALSE POSITIVE\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "#30     Test/train split                               #\n",
    "#   - split known_df into training and testing data.   #\n",
    "########################################################\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "#40     Scale                              #\n",
    "#   a- create standard scaler (ss) data.   #\n",
    "#   b- create minmax scaled (mm) data.     #\n",
    "############################################\n",
    "\n",
    "#a\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaler_ss = StandardScaler().fit(X_train)\n",
    "X_train_scaled_ss = X_scaler_ss.transform(X_train)\n",
    "X_test_scaled_ss = X_scaler_ss.transform(X_test)\n",
    "\n",
    "#b\n",
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "X_scaler_mm = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled_mm = X_scaler_mm.transform(X_train)\n",
    "X_test_scaled_mm = X_scaler_mm.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "#50      Compare df                                  #\n",
    "#   - create df to hold metrics of various models.   #\n",
    "#   model = model used (ie. linearRegression).       #\n",
    "#   scale code from 40-Scale above, 00 = none.       #\n",
    "#   train_score = r2 score from training data.       #\n",
    "#   test_score = r2 score from test data.            #\n",
    "#   avg = average train/test score.                  #\n",
    "######################################################\n",
    "\n",
    "compare_df = pd.DataFrame({\"model\":[], \"scale_code\":[], \"train_score\":[], \"test_score\":[], \"avg\":[]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "#100.00    Linear Regression no scale   #\n",
    "#   a- create and fit model.            #\n",
    "#   b- create and append df row.        #\n",
    "#########################################\n",
    "\n",
    "#a \n",
    "from sklearn.linear_model import LinearRegression\n",
    "model_100 = LinearRegression()\n",
    "model_100.fit(X_train, y_train)\n",
    "\n",
    "#b\n",
    "model = \"Linear Regression\"\n",
    "scale = \"00\"\n",
    "train = model_100.score(X_train, y_train)\n",
    "test = model_100.score(X_test, y_test)\n",
    "avg = (train+test)/2\n",
    "row = [model, scale, train, test, avg]\n",
    "compare_df = compare_df.append(pd.DataFrame([row], columns=compare_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "#100.ss    Linear Regression ss scale   #\n",
    "#   a- create and fit model.            #\n",
    "#   b- create and append df row.        #\n",
    "#########################################\n",
    "\n",
    "#a \n",
    "model_100S = LinearRegression()\n",
    "model_100S.fit(X_train_scaled_ss, y_train)\n",
    "\n",
    "#b\n",
    "model = \"Linear Regression\"\n",
    "scale = \"ss\"\n",
    "train = model_100.score(X_train_scaled_ss, y_train)\n",
    "test = model_100.score(X_test_scaled_ss, y_test)\n",
    "avg = (train+test)/2\n",
    "row = [model, scale, train, test, avg]\n",
    "compare_df = compare_df.append(pd.DataFrame([row], columns=compare_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "#100.mm    Linear Regression mm scale   #\n",
    "#   a- create and fit model.            #\n",
    "#   b- create and append df row.        #\n",
    "#########################################\n",
    "\n",
    "#a \n",
    "model_100m = LinearRegression()\n",
    "model_100m.fit(X_train_scaled_mm, y_train)\n",
    "\n",
    "#b\n",
    "model = \"Linear Regression\"\n",
    "scale = \"mm\"\n",
    "train = model_100m.score(X_train_scaled_mm, y_train)\n",
    "test = model_100m.score(X_test_scaled_mm, y_test)\n",
    "avg = (train+test)/2\n",
    "row = [model, scale, train, test, avg]\n",
    "compare_df = compare_df.append(pd.DataFrame([row], columns=compare_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#110.00    Lasso no scale          #\n",
    "#   a- create and fit model.       #\n",
    "#   b- create and append df row.   #\n",
    "####################################\n",
    "\n",
    "#a \n",
    "from sklearn.linear_model import Lasso\n",
    "lasso_110 = Lasso(alpha=.01).fit(X_train, y_train)\n",
    "\n",
    "#b\n",
    "model = \"Lasso\"\n",
    "scale = \"00\"\n",
    "train = lasso_110.score(X_train, y_train)\n",
    "test = lasso_110.score(X_test, y_test)\n",
    "avg = (train+test)/2\n",
    "row = [model, scale, train, test, avg]\n",
    "compare_df = compare_df.append(pd.DataFrame([row], columns=compare_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#110.ss    Lasso ss scale          #\n",
    "#   a- create and fit model.       #\n",
    "#   b- create and append df row.   #\n",
    "####################################\n",
    "\n",
    "#a \n",
    "lasso_110s = Lasso(alpha=.01).fit(X_train_scaled_ss, y_train)\n",
    "\n",
    "#b\n",
    "model = \"Lasso\"\n",
    "scale = \"ss\"\n",
    "train = lasso_110s.score(X_train_scaled_ss, y_train)\n",
    "test = lasso_110s.score(X_test_scaled_ss, y_test)\n",
    "avg = (train+test)/2\n",
    "row = [model, scale, train, test, avg]\n",
    "compare_df = compare_df.append(pd.DataFrame([row], columns=compare_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#110.mm    Lasso mm scale          #\n",
    "#   a- create and fit model.       #\n",
    "#   b- create and append df row.   #\n",
    "####################################\n",
    "\n",
    "#a \n",
    "lasso_110m = Lasso(alpha=.01).fit(X_train_scaled_mm, y_train)\n",
    "\n",
    "#b\n",
    "model = \"Lasso\"\n",
    "scale = \"mm\"\n",
    "train = lasso_110m.score(X_train_scaled_mm, y_train)\n",
    "test = lasso_110m.score(X_test_scaled_mm, y_test)\n",
    "avg = (train+test)/2\n",
    "row = [model, scale, train, test, avg]\n",
    "compare_df = compare_df.append(pd.DataFrame([row], columns=compare_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#120.00    Ridge no scale          #\n",
    "#   a- create and fit model.       #\n",
    "#   b- create and append df row.   #\n",
    "####################################\n",
    "\n",
    "#a \n",
    "from sklearn.linear_model import Ridge\n",
    "ridge_120 = Ridge(alpha=.01).fit(X_train, y_train)\n",
    "\n",
    "#b\n",
    "model = \"Ridge\"\n",
    "scale = \"00\"\n",
    "train = ridge_120.score(X_train, y_train)\n",
    "test = ridge_120.score(X_test, y_test)\n",
    "avg = (train+test)/2\n",
    "row = [model, scale, train, test, avg]\n",
    "compare_df = compare_df.append(pd.DataFrame([row], columns=compare_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#120.00    Ridge ss scale          #\n",
    "#   a- create and fit model        #\n",
    "#   b- create and append df row.   #\n",
    "####################################\n",
    "\n",
    "#a \n",
    "ridge_120s = Ridge(alpha=.01).fit(X_train_scaled_ss, y_train)\n",
    "\n",
    "#b\n",
    "model = \"Ridge\"\n",
    "scale = \"ss\"\n",
    "train = ridge_120s.score(X_train_scaled_ss, y_train)\n",
    "test = ridge_120s.score(X_test_scaled_ss, y_test)\n",
    "avg = (train+test)/2\n",
    "row = [model, scale, train, test, avg]\n",
    "compare_df = compare_df.append(pd.DataFrame([row], columns=compare_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#120.00    Ridge mm scale          #\n",
    "#   a- create and fit model.       #\n",
    "#   b- create and append df row.   #\n",
    "####################################\n",
    "\n",
    "#a \n",
    "ridge_120m = Ridge(alpha=.01).fit(X_train_scaled_mm, y_train)\n",
    "\n",
    "#b\n",
    "model = \"Ridge\"\n",
    "scale = \"mm\"\n",
    "train = ridge_120m.score(X_train_scaled_mm, y_train)\n",
    "test = ridge_120m.score(X_test_scaled_mm, y_test)\n",
    "avg = (train+test)/2\n",
    "row = [model, scale, train, test, avg]\n",
    "compare_df = compare_df.append(pd.DataFrame([row], columns=compare_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#130.00    ElasticNet no scale     #\n",
    "#   a- create and fit model.       #\n",
    "#   b- create and append df row.   #\n",
    "####################################\n",
    "\n",
    "#a \n",
    "from sklearn.linear_model import ElasticNet\n",
    "elasticnet_130 = ElasticNet(alpha=.01).fit(X_train, y_train)\n",
    "\n",
    "#b\n",
    "model = \"ElasticNet\"\n",
    "scale = \"00\"\n",
    "train = elasticnet_130.score(X_train, y_train)\n",
    "test = elasticnet_130.score(X_test, y_test)\n",
    "avg = (train+test)/2\n",
    "row = [model, scale, train, test, avg]\n",
    "compare_df = compare_df.append(pd.DataFrame([row], columns=compare_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#130.ss    ElasticNet ss scale     #\n",
    "#   a- create and fit model.       #\n",
    "#   b- create and append df row.   #\n",
    "####################################\n",
    "\n",
    "#a \n",
    "elasticnet_130s = ElasticNet(alpha=.01).fit(X_train_scaled_ss, y_train)\n",
    "\n",
    "#b\n",
    "model = \"ElasticNet\"\n",
    "scale = \"ss\"\n",
    "train = elasticnet_130s.score(X_train_scaled_ss, y_train)\n",
    "test = elasticnet_130s.score(X_test_scaled_ss, y_test)\n",
    "avg = (train+test)/2\n",
    "row = [model, scale, train, test, avg]\n",
    "compare_df = compare_df.append(pd.DataFrame([row], columns=compare_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#130.mm    ElasticNet mm scale     #\n",
    "#   a- create and fit model.       #\n",
    "#   b- create and append df row.   #\n",
    "####################################\n",
    "\n",
    "#a \n",
    "elasticnet_130m = ElasticNet(alpha=.01).fit(X_train_scaled_mm, y_train)\n",
    "\n",
    "#b\n",
    "model = \"ElasticNet\"\n",
    "scale = \"mm\"\n",
    "train = elasticnet_130m.score(X_train_scaled_mm, y_train)\n",
    "test = elasticnet_130m.score(X_test_scaled_mm, y_test)\n",
    "avg = (train+test)/2\n",
    "row = [model, scale, train, test, avg]\n",
    "compare_df = compare_df.append(pd.DataFrame([row], columns=compare_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "#140.00    LogisticRegression no scale   #\n",
    "#   a- create and fit model.             #\n",
    "#   b- create and append df row.         #\n",
    "##########################################\n",
    "\n",
    "#a \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier_140 = LogisticRegression()\n",
    "classifier_140.fit(X_train, y_train)\n",
    "\n",
    "#b\n",
    "model = \"LogisticRegression\"\n",
    "scale = \"00\"\n",
    "train = classifier_140.score(X_train, y_train)\n",
    "test = classifier_140.score(X_test, y_test)\n",
    "avg = (train+test)/2\n",
    "row = [model, scale, train, test, avg]\n",
    "compare_df = compare_df.append(pd.DataFrame([row], columns=compare_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "#140.ss    LogisticRegression ss scale   #\n",
    "#   a- create and fit model.             #\n",
    "#   b- create and append df row.         #\n",
    "##########################################\n",
    "\n",
    "#a \n",
    "classifier_140s = LogisticRegression()\n",
    "classifier_140s.fit(X_train_scaled_ss, y_train)\n",
    "\n",
    "#b\n",
    "model = \"LogisticRegression\"\n",
    "scale = \"ss\"\n",
    "train = classifier_140s.score(X_train_scaled_ss, y_train)\n",
    "test = classifier_140s.score(X_test_scaled_ss, y_test)\n",
    "avg = (train+test)/2\n",
    "row = [model, scale, train, test, avg]\n",
    "compare_df = compare_df.append(pd.DataFrame([row], columns=compare_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "#140.mm    LogisticRegression mm scale   #\n",
    "#   a- create and fit model.             #\n",
    "#   b- create and append df row.         #\n",
    "##########################################\n",
    "\n",
    "#a \n",
    "classifier_140m = LogisticRegression()\n",
    "classifier_140m.fit(X_train_scaled_mm, y_train)\n",
    "\n",
    "#b\n",
    "model = \"LogisticRegression\"\n",
    "scale = \"mm\"\n",
    "train = classifier_140m.score(X_train_scaled_mm, y_train)\n",
    "test = classifier_140m.score(X_test_scaled_mm, y_test)\n",
    "avg = (train+test)/2\n",
    "row = [model, scale, train, test, avg]\n",
    "compare_df = compare_df.append(pd.DataFrame([row], columns=compare_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#150.00    DecisionTree no scale   #\n",
    "#   a- create and fit model.       #\n",
    "#   b- create and append df row.   #\n",
    "####################################\n",
    "\n",
    "#a \n",
    "from sklearn import tree\n",
    "clf_150 = tree.DecisionTreeClassifier()\n",
    "clf_150 = clf_150.fit(X_train, y_train)\n",
    "\n",
    "#b\n",
    "model = \"DecisionTree\"\n",
    "scale = \"00\"\n",
    "train = clf_150.score(X_train, y_train)\n",
    "test = clf_150.score(X_test, y_test)\n",
    "avg = (train+test)/2\n",
    "row = [model, scale, train, test, avg]\n",
    "compare_df = compare_df.append(pd.DataFrame([row], columns=compare_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#150.ss    DecisionTree ss scale   #\n",
    "#   a- create and fit model.       #\n",
    "#   b- create and append df row.   #\n",
    "####################################\n",
    "\n",
    "#a \n",
    "clf_150s = tree.DecisionTreeClassifier()\n",
    "clf_150s = clf_150s.fit(X_train_scaled_ss, y_train)\n",
    "\n",
    "#b\n",
    "model = \"DecisionTree\"\n",
    "scale = \"ss\"\n",
    "train = clf_150s.score(X_train_scaled_ss, y_train)\n",
    "test = clf_150s.score(X_test_scaled_ss, y_test)\n",
    "avg = (train+test)/2\n",
    "row = [model, scale, train, test, avg]\n",
    "compare_df = compare_df.append(pd.DataFrame([row], columns=compare_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#150.mm    DecisionTree mm scale   #\n",
    "#   a- create and fit model.       #\n",
    "#   b- create and append df row.   #\n",
    "####################################\n",
    "\n",
    "#a \n",
    "clf_150m = tree.DecisionTreeClassifier()\n",
    "clf_150m = clf_150m.fit(X_train_scaled_mm, y_train)\n",
    "\n",
    "#b\n",
    "model = \"DecisionTree\"\n",
    "scale = \"mm\"\n",
    "train = clf_150m.score(X_train_scaled_mm, y_train)\n",
    "test = clf_150m.score(X_test_scaled_mm, y_test)\n",
    "avg = (train+test)/2\n",
    "row = [model, scale, train, test, avg]\n",
    "compare_df = compare_df.append(pd.DataFrame([row], columns=compare_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####################################\n",
    "#160.00    RandomForest no scale   #\n",
    "#   a- create and fit model.       #\n",
    "#   b- create and append df row.   #\n",
    "####################################\n",
    "\n",
    "#a \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_160 = RandomForestClassifier(n_estimators=200)\n",
    "rf_160 = rf_160.fit(X_train, y_train)\n",
    "\n",
    "#b\n",
    "model = \"RandomForest\"\n",
    "scale = \"00\"\n",
    "train = rf_160.score(X_train, y_train)\n",
    "test = rf_160.score(X_test, y_test)\n",
    "avg = (train+test)/2\n",
    "row = [model, scale, train, test, avg]\n",
    "compare_df = compare_df.append(pd.DataFrame([row], columns=compare_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#160.ss    RandomForest ss scale   #\n",
    "#   a- create and fit model.       #\n",
    "#   b- create and append df row.   #\n",
    "####################################\n",
    "\n",
    "#a \n",
    "rf_160s = RandomForestClassifier(n_estimators=200)\n",
    "rf_160s = rf_160s.fit(X_train_scaled_ss, y_train)\n",
    "\n",
    "#b\n",
    "model = \"RandomForest\"\n",
    "scale = \"ss\"\n",
    "train = rf_160s.score(X_train_scaled_ss, y_train)\n",
    "test = rf_160s.score(X_test_scaled_ss, y_test)\n",
    "avg = (train+test)/2\n",
    "row = [model, scale, train, test, avg]\n",
    "compare_df = compare_df.append(pd.DataFrame([row], columns=compare_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#160.mm    RandomForest mm scale   #\n",
    "#   a- create and fit model.       #\n",
    "#   b- create and append df row.   #\n",
    "####################################\n",
    "\n",
    "#a \n",
    "rf_160m = RandomForestClassifier(n_estimators=200)\n",
    "rf_160m = rf_160m.fit(X_train_scaled_mm, y_train)\n",
    "\n",
    "#b\n",
    "model = \"RandomForest\"\n",
    "scale = \"mm\"\n",
    "train = rf_160m.score(X_train_scaled_mm, y_train)\n",
    "test = rf_160m.score(X_test_scaled_mm, y_test)\n",
    "avg = (train+test)/2\n",
    "row = [model, scale, train, test, avg]\n",
    "compare_df = compare_df.append(pd.DataFrame([row], columns=compare_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##################################################################\n",
    "#170.00    KNN no scale                                          #\n",
    "#   a- create and fit model.                                     #\n",
    "#   b- create and append df row.                                 #\n",
    "#    - using neighbors = 33 as that is where test/train cross.   #\n",
    "##################################################################\n",
    "\n",
    "#a \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_170 = KNeighborsClassifier(n_neighbors=33)\n",
    "knn_170.fit(X_train, y_train)\n",
    "\n",
    "#b\n",
    "model = \"KNN\"\n",
    "scale = \"00\"\n",
    "train = knn_170.score(X_train, y_train)\n",
    "test = knn_170.score(X_test, y_test)\n",
    "avg = (train+test)/2\n",
    "row = [model, scale, train, test, avg]\n",
    "compare_df = compare_df.append(pd.DataFrame([row], columns=compare_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#170.ss    KNN ss scale            #\n",
    "#   a- create and fit model.       #\n",
    "#   b- create and append df row.   #\n",
    "####################################\n",
    "\n",
    "#a \n",
    "knn_170s = KNeighborsClassifier(n_neighbors=33)\n",
    "knn_170s.fit(X_train_scaled_ss, y_train)\n",
    "\n",
    "#b\n",
    "model = \"KNN\"\n",
    "scale = \"ss\"\n",
    "train = knn_170s.score(X_train_scaled_ss, y_train)\n",
    "test = knn_170s.score(X_test_scaled_ss, y_test)\n",
    "avg = (train+test)/2\n",
    "row = [model, scale, train, test, avg]\n",
    "compare_df = compare_df.append(pd.DataFrame([row], columns=compare_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#170.mm    KNN mm scale            #\n",
    "#   a- create and fit model.       #\n",
    "#   b- create and append df row.   #\n",
    "####################################\n",
    "\n",
    "#a \n",
    "knn_170m = KNeighborsClassifier(n_neighbors=33)\n",
    "knn_170m.fit(X_train_scaled_mm, y_train)\n",
    "\n",
    "#b\n",
    "model = \"KNN\"\n",
    "scale = \"mm\"\n",
    "train = knn_170m.score(X_train_scaled_mm, y_train)\n",
    "test = knn_170m.score(X_test_scaled_mm, y_test)\n",
    "avg = (train+test)/2\n",
    "row = [model, scale, train, test, avg]\n",
    "compare_df = compare_df.append(pd.DataFrame([row], columns=compare_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#180.00   SVC no scale                         #\n",
    "#   a- create and fit model.                   #\n",
    "#   b- create and append df row.               #\n",
    "#   ** this routine takes ~15 minutes to run   #\n",
    "#       and returns the following row...       #\n",
    "#  SVC\t00\t0.957014\t0.950226\t0.953620   #\n",
    "################################################\n",
    "\n",
    "# #a \n",
    "# from sklearn.svm import SVC \n",
    "# model_180 = SVC(kernel='linear')\n",
    "# model_180.fit(X_train, y_train)\n",
    "\n",
    "# #b\n",
    "# model = \"SVC\"\n",
    "# scale = \"00\"\n",
    "# train = model_180.score(X_train, y_train)\n",
    "# test = model_180.score(X_test, y_test)\n",
    "# avg = (train+test)/2\n",
    "# row = [model, scale, train, test, avg]\n",
    "# compare_df = compare_df.append(pd.DataFrame([row], columns=compare_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#180.ss    SVC ss scale            #\n",
    "#   a- create and fit model.       #\n",
    "#   b- create and append df row.   #\n",
    "####################################\n",
    "\n",
    "#a \n",
    "from sklearn.svm import SVC \n",
    "model_180s = SVC(kernel='linear')\n",
    "model_180s.fit(X_train_scaled_ss, y_train)\n",
    "\n",
    "#b\n",
    "model = \"SVC\"\n",
    "scale = \"ss\"\n",
    "train = model_180s.score(X_train_scaled_ss, y_train)\n",
    "test = model_180s.score(X_test_scaled_ss, y_test)\n",
    "avg = (train+test)/2\n",
    "row = [model, scale, train, test, avg]\n",
    "compare_df = compare_df.append(pd.DataFrame([row], columns=compare_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####################################\n",
    "#180.mm    SVC mm scale            #\n",
    "#   a- create and fit model.       #\n",
    "#   b- create and append df row.   #\n",
    "####################################\n",
    "\n",
    "#a \n",
    "model_180m = SVC(kernel='linear')\n",
    "model_180m.fit(X_train_scaled_mm, y_train)\n",
    "\n",
    "#b\n",
    "model = \"SVC\"\n",
    "scale = \"mm\"\n",
    "train = model_180m.score(X_train_scaled_mm, y_train)\n",
    "test = model_180m.score(X_test_scaled_mm, y_test)\n",
    "avg = (train+test)/2\n",
    "row = [model, scale, train, test, avg]\n",
    "compare_df = compare_df.append(pd.DataFrame([row], columns=compare_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>scale_code</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985671</td>\n",
       "      <td>0.992836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>ss</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984917</td>\n",
       "      <td>0.992459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>mm</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983409</td>\n",
       "      <td>0.991704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>mm</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979638</td>\n",
       "      <td>0.989819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979638</td>\n",
       "      <td>0.989819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>ss</td>\n",
       "      <td>0.992459</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.989442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>ss</td>\n",
       "      <td>0.992961</td>\n",
       "      <td>0.985671</td>\n",
       "      <td>0.989316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ss</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978130</td>\n",
       "      <td>0.989065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>mm</td>\n",
       "      <td>0.991956</td>\n",
       "      <td>0.985671</td>\n",
       "      <td>0.988813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>mm</td>\n",
       "      <td>0.991956</td>\n",
       "      <td>0.985671</td>\n",
       "      <td>0.988813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>mm</td>\n",
       "      <td>0.991956</td>\n",
       "      <td>0.985671</td>\n",
       "      <td>0.988813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>ss</td>\n",
       "      <td>0.973102</td>\n",
       "      <td>0.972851</td>\n",
       "      <td>0.972976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>00</td>\n",
       "      <td>0.855958</td>\n",
       "      <td>0.843891</td>\n",
       "      <td>0.849925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>00</td>\n",
       "      <td>0.829311</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.818879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>ss</td>\n",
       "      <td>0.770991</td>\n",
       "      <td>0.750460</td>\n",
       "      <td>0.760726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>00</td>\n",
       "      <td>0.770991</td>\n",
       "      <td>0.750459</td>\n",
       "      <td>0.760725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>mm</td>\n",
       "      <td>0.770991</td>\n",
       "      <td>0.750459</td>\n",
       "      <td>0.760725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>00</td>\n",
       "      <td>0.770990</td>\n",
       "      <td>0.750437</td>\n",
       "      <td>0.760714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>mm</td>\n",
       "      <td>0.770937</td>\n",
       "      <td>0.750284</td>\n",
       "      <td>0.760611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>ss</td>\n",
       "      <td>0.766535</td>\n",
       "      <td>0.751175</td>\n",
       "      <td>0.758855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>ss</td>\n",
       "      <td>0.761850</td>\n",
       "      <td>0.748023</td>\n",
       "      <td>0.754936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>00</td>\n",
       "      <td>0.759048</td>\n",
       "      <td>0.746144</td>\n",
       "      <td>0.752596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>00</td>\n",
       "      <td>0.749769</td>\n",
       "      <td>0.737326</td>\n",
       "      <td>0.743548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>mm</td>\n",
       "      <td>0.710664</td>\n",
       "      <td>0.693041</td>\n",
       "      <td>0.701852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>mm</td>\n",
       "      <td>0.704809</td>\n",
       "      <td>0.688559</td>\n",
       "      <td>0.696684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>ss</td>\n",
       "      <td>-7.925801</td>\n",
       "      <td>-6.058446</td>\n",
       "      <td>-6.992123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model scale_code  train_score  test_score       avg\n",
       "0        DecisionTree         00     1.000000    0.985671  0.992836\n",
       "0        DecisionTree         ss     1.000000    0.984917  0.992459\n",
       "0        DecisionTree         mm     1.000000    0.983409  0.991704\n",
       "0        RandomForest         mm     1.000000    0.979638  0.989819\n",
       "0        RandomForest         00     1.000000    0.979638  0.989819\n",
       "0                 SVC         ss     0.992459    0.986425  0.989442\n",
       "0  LogisticRegression         ss     0.992961    0.985671  0.989316\n",
       "0        RandomForest         ss     1.000000    0.978130  0.989065\n",
       "0  LogisticRegression         mm     0.991956    0.985671  0.988813\n",
       "0                 KNN         mm     0.991956    0.985671  0.988813\n",
       "0                 SVC         mm     0.991956    0.985671  0.988813\n",
       "0                 KNN         ss     0.973102    0.972851  0.972976\n",
       "0  LogisticRegression         00     0.855958    0.843891  0.849925\n",
       "0                 KNN         00     0.829311    0.808446  0.818879\n",
       "0               Ridge         ss     0.770991    0.750460  0.760726\n",
       "0   Linear Regression         00     0.770991    0.750459  0.760725\n",
       "0   Linear Regression         mm     0.770991    0.750459  0.760725\n",
       "0               Ridge         00     0.770990    0.750437  0.760714\n",
       "0               Ridge         mm     0.770937    0.750284  0.760611\n",
       "0          ElasticNet         ss     0.766535    0.751175  0.758855\n",
       "0               Lasso         ss     0.761850    0.748023  0.754936\n",
       "0          ElasticNet         00     0.759048    0.746144  0.752596\n",
       "0               Lasso         00     0.749769    0.737326  0.743548\n",
       "0          ElasticNet         mm     0.710664    0.693041  0.701852\n",
       "0               Lasso         mm     0.704809    0.688559  0.696684\n",
       "0   Linear Regression         ss    -7.925801   -6.058446 -6.992123"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################################################\n",
    "#190     Write/Sort                             #\n",
    "#   - write compare_df to csv.                  #\n",
    "#   - sort df based on avg score and display.   #\n",
    "#################################################\n",
    "\n",
    "compare_df.to_csv(\"../data_out/methods_compare.csv\", index=False, header=True)\n",
    "\n",
    "compare_df.sort_values([\"avg\"], ascending = False, inplace=True)  \n",
    "compare_df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##  TOP 3 PERFORMERS (from initial run, subsequent runs show slight variations)\n",
    "1) DecisionTree (ss,mm,00)\n",
    "2) SVC (ss)\n",
    "3) RandomForest (00)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.000137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.000357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.000559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.000632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.000748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.000841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.001055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.001108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.001119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0.001119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.001122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0.001496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.001682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.001803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.001853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.002590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.002868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.005568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.008430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.065090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.133141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.149502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.269387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0.296176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     score\n",
       "0   35.0  0.000000\n",
       "0   22.0  0.000000\n",
       "0   20.0  0.000000\n",
       "0   16.0  0.000000\n",
       "0   36.0  0.000000\n",
       "0   24.0  0.000000\n",
       "0   30.0  0.000000\n",
       "0   27.0  0.000000\n",
       "0   32.0  0.000000\n",
       "0   31.0  0.000000\n",
       "0    6.0  0.000000\n",
       "0   33.0  0.000000\n",
       "0   14.0  0.000021\n",
       "0   21.0  0.000137\n",
       "0   11.0  0.000273\n",
       "0   13.0  0.000357\n",
       "0    4.0  0.000365\n",
       "0   28.0  0.000559\n",
       "0    9.0  0.000632\n",
       "0   34.0  0.000748\n",
       "0   23.0  0.000841\n",
       "0    8.0  0.001055\n",
       "0   38.0  0.001108\n",
       "0   12.0  0.001119\n",
       "0   37.0  0.001119\n",
       "0   10.0  0.001122\n",
       "0   39.0  0.001496\n",
       "0   25.0  0.001682\n",
       "0   17.0  0.001803\n",
       "0   15.0  0.001853\n",
       "0   18.0  0.002590\n",
       "0   26.0  0.002868\n",
       "0    5.0  0.005568\n",
       "0    7.0  0.008430\n",
       "0    1.0  0.050957\n",
       "0    3.0  0.065090\n",
       "0   19.0  0.133141\n",
       "0    0.0  0.149502\n",
       "0    2.0  0.269387\n",
       "0   29.0  0.296176"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################\n",
    "#200     DecisionTree (ss) features        #\n",
    "#   - list and plot features importance.   #\n",
    "############################################\n",
    "\n",
    "dt_feature_df = pd.DataFrame({\"index\":[], \"score\":[]})\n",
    "importance = clf_150s.feature_importances_\n",
    " \n",
    "for i,v in enumerate(importance):\n",
    "    dt_feature_df = dt_feature_df.append(pd.DataFrame([[i,v]], columns=dt_feature_df.columns))\n",
    "    \n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()\n",
    "\n",
    "dt_feature_df.sort_values([\"score\"], inplace=True)  \n",
    "dt_feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.081003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.065863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.971763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.886954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.0</td>\n",
       "      <td>-0.558608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.470535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.354462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>-0.142224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.0</td>\n",
       "      <td>-0.073417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.0</td>\n",
       "      <td>-0.064821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>-0.044967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>-0.044199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.0</td>\n",
       "      <td>-0.038268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.0</td>\n",
       "      <td>-0.034842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>-0.031126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>-0.030419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.019988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.017279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.0</td>\n",
       "      <td>-0.011996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.006635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.006635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.007918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.011984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.012264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.017050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0.017703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.019417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.021505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0.027958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.031126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.034842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.035091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.039282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.047376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.049137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.050456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0.052760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.054935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.113600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.354462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     score\n",
       "0    1.0 -1.081003\n",
       "0    2.0 -1.065863\n",
       "0    0.0 -0.971763\n",
       "0    3.0 -0.886954\n",
       "0   16.0 -0.558608\n",
       "0   10.0 -0.470535\n",
       "0    5.0 -0.354462\n",
       "0   12.0 -0.142224\n",
       "0   23.0 -0.073417\n",
       "0   35.0 -0.064821\n",
       "0   11.0 -0.044967\n",
       "0   22.0 -0.044199\n",
       "0   25.0 -0.038268\n",
       "0   14.0 -0.034842\n",
       "0   18.0 -0.031126\n",
       "0   19.0 -0.030419\n",
       "0   20.0 -0.019988\n",
       "0    7.0 -0.017279\n",
       "0   29.0 -0.011996\n",
       "0    9.0 -0.006635\n",
       "0    8.0  0.006635\n",
       "0   31.0  0.007918\n",
       "0   27.0  0.011984\n",
       "0   13.0  0.012264\n",
       "0   21.0  0.017050\n",
       "0   37.0  0.017703\n",
       "0   38.0  0.019417\n",
       "0   30.0  0.021505\n",
       "0   39.0  0.027958\n",
       "0   17.0  0.031126\n",
       "0   15.0  0.034842\n",
       "0   32.0  0.035091\n",
       "0   26.0  0.039282\n",
       "0   33.0  0.047376\n",
       "0   34.0  0.049137\n",
       "0   28.0  0.050456\n",
       "0   36.0  0.052760\n",
       "0    4.0  0.054935\n",
       "0   24.0  0.113600\n",
       "0    6.0  0.354462"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################\n",
    "#210     SVC (ss) features                 #\n",
    "#   - list and plot features importance.   #\n",
    "############################################\n",
    "\n",
    "svc_feature_df = pd.DataFrame({\"index\":[], \"score\":[]})\n",
    "importance = model_180s.coef_[0]\n",
    " \n",
    "for i,v in enumerate(importance):\n",
    "    svc_feature_df = svc_feature_df.append(pd.DataFrame([[i,v]], columns=svc_feature_df.columns))\n",
    "\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()\n",
    "\n",
    "svc_feature_df.sort_values([\"score\"], inplace=True)  \n",
    "svc_feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.002926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.003471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.003680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.003773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0.003848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.003935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0.004540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0.004999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.005301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.005406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.005773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.006550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.006712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.006965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.010520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.010680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.010742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.011690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.013892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.014527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.017652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.017893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.018051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.018071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.018079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.022107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.023034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.024743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.025320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.029242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.034387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.045333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.047437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.056551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.057271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.058903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.064767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0.072680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.138332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     score\n",
       "0   27.0  0.002926\n",
       "0   38.0  0.003471\n",
       "0   12.0  0.003680\n",
       "0   32.0  0.003773\n",
       "0   39.0  0.003848\n",
       "0   28.0  0.003935\n",
       "0   36.0  0.004540\n",
       "0   37.0  0.004999\n",
       "0   31.0  0.005301\n",
       "0   11.0  0.005406\n",
       "0   34.0  0.005773\n",
       "0   13.0  0.006550\n",
       "0    7.0  0.006712\n",
       "0   33.0  0.006965\n",
       "0   17.0  0.010520\n",
       "0    5.0  0.010680\n",
       "0    6.0  0.010742\n",
       "0   18.0  0.011690\n",
       "0   16.0  0.013892\n",
       "0   10.0  0.014527\n",
       "0   25.0  0.017652\n",
       "0   35.0  0.017893\n",
       "0   22.0  0.018051\n",
       "0    4.0  0.018071\n",
       "0   23.0  0.018079\n",
       "0   24.0  0.022107\n",
       "0    8.0  0.023034\n",
       "0    9.0  0.024743\n",
       "0   26.0  0.025320\n",
       "0    3.0  0.029242\n",
       "0   14.0  0.034387\n",
       "0   15.0  0.045333\n",
       "0   20.0  0.047437\n",
       "0   21.0  0.056551\n",
       "0   19.0  0.057271\n",
       "0   30.0  0.058903\n",
       "0    1.0  0.064767\n",
       "0    0.0  0.070220\n",
       "0   29.0  0.072680\n",
       "0    2.0  0.138332"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################\n",
    "#220     RandomForest (00) features        #\n",
    "#   - list and plot features importance.   #\n",
    "############################################\n",
    "\n",
    "rf_feature_df = pd.DataFrame({\"index\":[], \"score\":[]})\n",
    "importance = rf_160.feature_importances_\n",
    " \n",
    "for i,v in enumerate(importance):\n",
    "    rf_feature_df = rf_feature_df.append(pd.DataFrame([[i,v]], columns=rf_feature_df.columns))\n",
    "\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()\n",
    "\n",
    "rf_feature_df.sort_values([\"score\"], inplace=True)  \n",
    "rf_feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  1.0 test:  0.9849170437405732  avg:  0.9924585218702866\n",
      "trainX: 1.0 testX: 0.9841628959276018  avgx: 0.9920814479638009\n"
     ]
    }
   ],
   "source": [
    "############################################################################\n",
    "#300   DecisionTree(ss) feature selection                                  #\n",
    "#   a- remove columns with a score of 0.                                   #\n",
    "#   b- split new df and scale.                                             #\n",
    "#   c- run model on new data.                                              #\n",
    "#   d- recalculate original scores then new scores and print comparison.   #\n",
    "#   note- varying effect on score, generally better, use new model.        #\n",
    "############################################################################\n",
    "\n",
    "#a\n",
    "cols = [39,33,32,31,30,36,27,25,22,34,16,17,35,10,9]\n",
    "dt_df = X.drop(X.columns[cols],axis=1)\n",
    "\n",
    "#b\n",
    "dt_df_train, dt_df_test, y_train, y_test = train_test_split(dt_df, y, random_state=42)\n",
    "\n",
    "dt_df_scaler_ss = StandardScaler().fit(dt_df_train)\n",
    "dt_df_train_scaled_ss = dt_df_scaler_ss.transform(dt_df_train)\n",
    "dt_df_test_scaled_ss = dt_df_scaler_ss.transform(dt_df_test)\n",
    "\n",
    "#c\n",
    "clf_150sXXX = tree.DecisionTreeClassifier()\n",
    "clf_150sXXX = clf_150sXXX.fit(dt_df_train_scaled_ss, y_train)\n",
    "predictions_150sXXX = clf_150sXXX.predict(dt_df_test_scaled_ss)\n",
    "\n",
    "#d\n",
    "# original scores\n",
    "train = clf_150s.score(X_train_scaled_ss, y_train)\n",
    "test = clf_150s.score(X_test_scaled_ss, y_test)\n",
    "avg = (train+test)/2\n",
    "\n",
    "# new scores\n",
    "trainXXX = clf_150sXXX.score(dt_df_train_scaled_ss, y_train)\n",
    "testXXX = clf_150sXXX.score(dt_df_test_scaled_ss, y_test)\n",
    "avgXXX = (trainXXX+testXXX)/2\n",
    "\n",
    "# compare scores\n",
    "print(f\"train:  {train} test:  {test}  avg:  {avg}\")\n",
    "print(f\"trainX: {trainXXX} testX: {testXXX}  avgx: {avgXXX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0.9924585218702866 test:  0.9864253393665159  avg:  0.9894419306184012\n",
      "trainX: 0.8582202111613876 testX: 0.8408748114630468  avgx: 0.8495475113122172\n"
     ]
    }
   ],
   "source": [
    "############################################################################\n",
    "#310   SVC(ss) feature selection                                           #\n",
    "#   a- remove columns with a negative score.                               #\n",
    "#   b- split new df and scale.                                             #\n",
    "#   c- run model on new data.                                              #\n",
    "#   d- recalculate original scores then new scores and print comparison.   #\n",
    "#   note- significant reduction in score (see routine 311 below).          #\n",
    "############################################################################\n",
    "\n",
    "#a\n",
    "cols = [1,2,0,3,16,10,5,12,23,35,11,22,25,14,18,19,20,7,29,9]\n",
    "svc_df = X.drop(X.columns[cols],axis=1)\n",
    "\n",
    "#b\n",
    "svc_df_train, svc_df_test, y_train, y_test = train_test_split(svc_df, y, random_state=42)\n",
    "\n",
    "svc_df_scaler_ss = StandardScaler().fit(svc_df_train)\n",
    "svc_df_train_scaled_ss = svc_df_scaler_ss.transform(svc_df_train)\n",
    "svc_df_test_scaled_ss = svc_df_scaler_ss.transform(svc_df_test)\n",
    "\n",
    "#c\n",
    "model_180sXXX = SVC(kernel='linear')\n",
    "model_180sXXX.fit(svc_df_train_scaled_ss, y_train)\n",
    "predictions_180sXXX = model_180sXXX.predict(svc_df_train_scaled_ss)\n",
    "\n",
    "#d\n",
    "# original scores\n",
    "train = model_180s.score(X_train_scaled_ss, y_train)\n",
    "test = model_180s.score(X_test_scaled_ss, y_test)\n",
    "avg = (train+test)/2\n",
    "\n",
    "#  new scores\n",
    "trainXXX = model_180sXXX.score(svc_df_train_scaled_ss, y_train)\n",
    "testXXX = model_180sXXX.score(svc_df_test_scaled_ss, y_test)\n",
    "avgXXX = (trainXXX+testXXX)/2\n",
    "\n",
    "# compare scores\n",
    "print(f\"train:  {train} test:  {test}  avg:  {avg}\")\n",
    "print(f\"trainX: {trainXXX} testX: {testXXX}  avgx: {avgXXX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0.9924585218702866 test:  0.9864253393665159  avg:  0.9894419306184012\n",
      "trainX: 0.9924585218702866 testX: 0.9864253393665159  avgx: 0.9894419306184012\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "#311   SVC(ss) feature selection Part2                                        #\n",
    "#   - removing features from being dropped.                                   #\n",
    "#     - cols 5,9,23 had no affect, kept them dropped.                         #\n",
    "#     - cols 7,12,20,29 lowered score when not dropped, kept dropped.         #\n",
    "#     - cols 19,18,14,25,22,11,35,10,16,3,0,1,2 lowered score when dropped.   #\n",
    "#     - one by one removed features with lt 3% importance.                    #\n",
    "#      - 8,31,27,13,21,37,38 had no affect, kept them as dropped.             #\n",
    "#      - 30 & 39 lowered score.                                               #\n",
    "#   conclusion - removing features has a negative or no affect in scores,     #\n",
    "#                use new model with irrelevant features removed.              #\n",
    "###############################################################################\n",
    "\n",
    "#a\n",
    "cols = [12,20,7,9,29,5,23,8,31,27,13,21,37]\n",
    "svc_df = X.drop(X.columns[cols],axis=1)\n",
    "\n",
    "#b\n",
    "svc_df_train, svc_df_test, y_train, y_test = train_test_split(svc_df, y, random_state=42)\n",
    "svc_df_scaler_ss = StandardScaler().fit(svc_df_train)\n",
    "svc_df_train_scaled_ss = svc_df_scaler_ss.transform(svc_df_train)\n",
    "svc_df_test_scaled_ss = svc_df_scaler_ss.transform(svc_df_test)\n",
    "\n",
    "#c\n",
    "model_180sXXX = SVC(kernel='linear')\n",
    "model_180sXXX.fit(svc_df_train_scaled_ss, y_train)\n",
    "predictions_180sXXX = model_180sXXX.predict(svc_df_train_scaled_ss)\n",
    "\n",
    "#d\n",
    "# original scores\n",
    "train = model_180s.score(X_train_scaled_ss, y_train)\n",
    "test = model_180s.score(X_test_scaled_ss, y_test)\n",
    "avg = (train+test)/2\n",
    "\n",
    "#  new scores\n",
    "trainXXX = model_180sXXX.score(svc_df_train_scaled_ss, y_train)\n",
    "testXXX = model_180sXXX.score(svc_df_test_scaled_ss, y_test)\n",
    "avgXXX = (trainXXX+testXXX)/2\n",
    "\n",
    "# compare scores\n",
    "print(f\"train:  {train} test:  {test}  avg:  {avg}\")\n",
    "print(f\"trainX: {trainXXX} testX: {testXXX}  avgx: {avgXXX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  1.0 test:  0.9796380090497737  avg:  0.9898190045248869\n",
      "trainX: 1.0 testX: 0.9811463046757164  avgx: 0.9905731523378583\n"
     ]
    }
   ],
   "source": [
    "#########################################################################################\n",
    "#320   RandomForest (00) feature selection                                              #\n",
    "#   a- remove columns with score lt 1%.                                                 #\n",
    "#   b- split new df.                                                                    #\n",
    "#   c- run model on new data.                                                           #\n",
    "#   d- recalculate original scores then new scores and print comparison.                #\n",
    "#   note- varying results some with a slight increase in score, some slight decrease.   #\n",
    "#  conclusion - use new model (if nothing else, less overhead).                         #\n",
    "#########################################################################################\n",
    "\n",
    "#a\n",
    "cols = [27,38,12,28,32,36,37,39,31,11,34,7,13,17,5]\n",
    "rf_df = X.drop(X.columns[cols],axis=1)\n",
    "\n",
    "#b\n",
    "rf_df_train, rf_df_test, y_train, y_test = train_test_split(rf_df, y, random_state=42)\n",
    "\n",
    "#c\n",
    "rf_160XXX = RandomForestClassifier(n_estimators=200)\n",
    "rf_160XXX = rf_160XXX.fit(rf_df_train, y_train)\n",
    "predictions_160XXX = rf_160XXX.predict(rf_df_test)\n",
    "\n",
    "#d\n",
    "# original scores\n",
    "train = rf_160.score(X_train, y_train)\n",
    "test = rf_160.score(X_test, y_test)\n",
    "avg = (train+test)/2\n",
    "\n",
    "#  new scores\n",
    "trainXXX = rf_160XXX.score(rf_df_train, y_train)\n",
    "testXXX = rf_160XXX.score(rf_df_test, y_test)\n",
    "avgXXX = (trainXXX+testXXX)/2\n",
    "\n",
    "# compare scores\n",
    "print(f\"train:  {train} test:  {test}  avg:  {avg}\")\n",
    "print(f\"trainX: {trainXXX} testX: {testXXX}  avgx: {avgXXX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "#400    ModelParameters                      #\n",
    "#   - print off parameters of top3 models.   #\n",
    "##############################################\n",
    "\n",
    "print(clf_150s)\n",
    "print(\"-\" * 100)\n",
    "print(model_180s)\n",
    "print(\"-\" * 100)\n",
    "print(rf_160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort='deprecated',\n",
       "                                              random_state=None,\n",
       "                                              splitter='best'),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'ccp_alpha': [0, 0.01, 0.1, 1],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2', <class 'int'>,\n",
       "                                          <class 'float'>, None],\n",
       "                         'splitter': ['random', 'best']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################\n",
    "#410   DecisionTree GridSearch                #\n",
    "#   - run gridsearch on various parameters.   #\n",
    "###############################################\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\"splitter\": [\"random\", \"best\"],\n",
    "              \"max_features\": [\"auto\", \"sqrt\", \"log2\", int, float, None],\n",
    "              \"ccp_alpha\":[0, 0.01, 0.1, 1]}\n",
    "dt_grid = GridSearchCV(clf_150s, param_grid, verbose=0)\n",
    "dt_grid.fit(dt_df_train_scaled_ss, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ccp_alpha': 0.01, 'max_features': None, 'splitter': 'random'}\n",
      "0.991957586675516\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CONFIRMED       0.98      1.00      0.99       875\n",
      "FALSE POSITIVE       1.00      0.96      0.98       451\n",
      "\n",
      "      accuracy                           0.99      1326\n",
      "     macro avg       0.99      0.98      0.98      1326\n",
      "  weighted avg       0.99      0.99      0.99      1326\n",
      "\n",
      "original test score:    0.9849170437405732\n",
      "dropped features score: 0.9841628959276018\n",
      "hypertuned test  score: 0.991957586675516\n"
     ]
    }
   ],
   "source": [
    "###########################################################\n",
    "#420   DecisionTree GridResult                            #\n",
    "#   - print best params and score.                        # \n",
    "#   - make predictions and print classification report.   #\n",
    "#   - print comparison of test scores.                    #\n",
    "###########################################################\n",
    "\n",
    "print(dt_grid.best_params_)\n",
    "print(dt_grid.best_score_)\n",
    "predictions_420 = dt_grid.predict(dt_df_test_scaled_ss)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions_420,\n",
    "                            target_names=[\"CONFIRMED\", \"FALSE POSITIVE\"]))\n",
    "\n",
    "print(f\"original test score:    {clf_150s.score(X_test_scaled_ss, y_test)}\")\n",
    "print(f\"dropped features score: {clf_150sXXX.score(dt_df_test_scaled_ss, y_test)}\")\n",
    "print(f\"hypertuned test  score: {dt_grid.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='linear', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [1, 5, 10, 50],\n",
       "                         'gamma': [0.0001, 0.0005, 0.001, 0.005],\n",
       "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################\n",
    "#430   SVC GridSearch                         #\n",
    "#   - run gridsearch on various parameters.   #\n",
    "###############################################\n",
    "\n",
    "param_grid = {\"C\": [1, 5, 10, 50],\n",
    "              \"gamma\": [0.0001, 0.0005, 0.001, 0.005],\n",
    "              \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]}\n",
    "svc_grid = GridSearchCV(model_180s, param_grid, verbose=0)\n",
    "svc_grid.fit(svc_df_train_scaled_ss, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 5, 'gamma': 0.0001, 'kernel': 'linear'}\n",
      "0.9922088429569229\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CONFIRMED       0.98      1.00      0.99       875\n",
      "FALSE POSITIVE       1.00      0.96      0.98       451\n",
      "\n",
      "      accuracy                           0.99      1326\n",
      "     macro avg       0.99      0.98      0.98      1326\n",
      "  weighted avg       0.99      0.99      0.99      1326\n",
      "\n",
      "original test score:    0.9864253393665159\n",
      "dropped features score: 0.9864253393665159\n",
      "hypertuned test  score: 0.9922088429569229\n"
     ]
    }
   ],
   "source": [
    "###########################################################\n",
    "#440   SVC GridResult                                     #\n",
    "#   - print best params and score.                        # \n",
    "#   - make predictions and print classification report.   #\n",
    "#   - print comparison of test scores.                    #\n",
    "###########################################################\n",
    "\n",
    "print(svc_grid.best_params_)\n",
    "print(svc_grid.best_score_)\n",
    "predictions_440 = svc_grid.predict(svc_df_test_scaled_ss)\n",
    "\n",
    "print(classification_report(y_test, predictions_440,\n",
    "                            target_names=[\"CONFIRMED\", \"FALSE POSITIVE\"]))\n",
    "\n",
    "print(f\"original test score:    {model_180s.score(X_test_scaled_ss, y_test)}\")\n",
    "print(f\"dropped features score: {model_180sXXX.score(svc_df_test_scaled_ss, y_test)}\")\n",
    "print(f\"hypertuned test  score: {svc_grid.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=200, n_jobs=No...\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'ccp_alpha': [0, 0.01, 0.1, 1, 10],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2', <class 'int'>,\n",
       "                                          <class 'float'>, None],\n",
       "                         'n_estimators': [10, 100, 200, 500],\n",
       "                         'random_state': [<class 'int'>, 'RandomState', None]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################\n",
    "#450   RandomForest GridSearch                #\n",
    "#   - run gridsearch on various parameters.   # \n",
    "###############################################\n",
    "\n",
    "param_grid = {\"n_estimators\": [10, 100, 200, 500],\n",
    "              \"max_features\": [\"auto\", \"sqrt\", \"log2\", int, float, None],\n",
    "              \"ccp_alpha\": [0, 0.01, 0.1, 1, 10],\n",
    "              \"random_state\": [int, \"RandomState\", None]}\n",
    "rf_grid = GridSearchCV(rf_160, param_grid, verbose=0)\n",
    "rf_grid.fit(rf_df_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ccp_alpha': 0, 'max_features': None, 'n_estimators': 100, 'random_state': None}\n",
      "0.991453809930154\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CONFIRMED       0.98      1.00      0.99       875\n",
      "FALSE POSITIVE       1.00      0.97      0.98       451\n",
      "\n",
      "      accuracy                           0.99      1326\n",
      "     macro avg       0.99      0.98      0.99      1326\n",
      "  weighted avg       0.99      0.99      0.99      1326\n",
      "\n",
      "original test score:    0.9796380090497737\n",
      "dropped features score: 0.9811463046757164\n",
      "hypertuned test  score: 0.991453809930154\n"
     ]
    }
   ],
   "source": [
    "###########################################################\n",
    "#460   RandomForest GridResult                            #\n",
    "#   - print best params and score.                        # \n",
    "#   - make predictions and print classification report.   #\n",
    "#   - print comparison of test scores.                    #\n",
    "###########################################################\n",
    "\n",
    "print(rf_grid.best_params_)\n",
    "print(rf_grid.best_score_)\n",
    "predictions_460 = rf_grid.predict(rf_df_test)\n",
    "\n",
    "print(classification_report(y_test, predictions_460,\n",
    "                            target_names=[\"CONFIRMED\", \"FALSE POSITIVE\"]))\n",
    "\n",
    "print(f\"original test score:    {rf_160.score(X_test, y_test)}\")\n",
    "print(f\"dropped features score: {rf_160XXX.score(rf_df_test, y_test)}\")\n",
    "print(f\"hypertuned test  score: {rf_grid.best_score_}\")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
