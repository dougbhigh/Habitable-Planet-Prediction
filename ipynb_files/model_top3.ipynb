{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "#  RUT-SOM-DATA-PT-06-2020-U-C                                                    Douglas High #\n",
    "#   Machine-Learning-Challenge                                                November 7, 2020 #\n",
    "#         > model_top3.ipynb                                                                   #\n",
    "#    - run the top 3 models against the 1687 unknown 'candidate' records.                      #\n",
    "#    - save each df with predictions to csv.                                                   #\n",
    "#    > results                                                                                 #\n",
    "#      - svc model only predicted 3 confirmed planets and 1684 false positive.                 #\n",
    "#      - DecisionTree predicted 1665 confirmed and 22 false positive.                          #\n",
    "#      - RandomForest predicted 1515 confirmed and 172 false positive.                         #\n",
    "################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "#00.UI     Update/Install                                                   #\n",
    "#    a- install/check for update sklearn (to prevent version mismatches).   #\n",
    "#    b- install joblib - used to save model (uncomment to install).         #\n",
    "#       *** Restart Kernal after joblib install ***                         #\n",
    "#############################################################################\n",
    "\n",
    "#a\n",
    "!pip install sklearn --upgrade\n",
    "\n",
    "#b\n",
    "# !pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "#00   I/O                 #\n",
    "#   - import libraries.   #\n",
    "#   - associate files.    #\n",
    "###########################\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "data_in = \"../data_in/exoplanet_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "#10     Read and remove                                          #\n",
    "#   - read data into df.                                         #\n",
    "#   - drop null columns if all values are null.                  #\n",
    "#   - drop null rows.                                            #\n",
    "#   - split data into known values (confirmed, false positive)   #\n",
    "#     and unknown (candidate).                                   #\n",
    "##################################################################\n",
    "\n",
    "df = pd.read_csv(data_in)\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "df = df.dropna()\n",
    "\n",
    "known_df = df[df[\"koi_disposition\"] != \"CANDIDATE\"]\n",
    "unknown_df = df[df[\"koi_disposition\"] == \"CANDIDATE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "#20     Set Features                                         #\n",
    "#   a- select all columns to use as features                 #\n",
    "#    - disposition is the dependent variable.                #\n",
    "#   b- drop columns based on results from module0_compare.   #\n",
    "##############################################################\n",
    "\n",
    "#a\n",
    "X = known_df.drop(\"koi_disposition\", axis=1)\n",
    "y = known_df[\"koi_disposition\"]\n",
    "\n",
    "#b\n",
    "cols = [39,33,32,31,30,36,27,25,22,34,16,17,35,10,9]\n",
    "dt_df = X.drop(X.columns[cols],axis=1)\n",
    "\n",
    "cols = [12,20,7,9,29,5,23,8,31,27,13,21,37]\n",
    "svc_df = X.drop(X.columns[cols],axis=1)\n",
    "\n",
    "cols = [27,38,12,28,32,36,37,39,31,11,34,7,13,17,5]\n",
    "rf_df = X.drop(X.columns[cols],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "#30     Test/train split                                              #\n",
    "#   - split known_df into training and testing data for each model.   #\n",
    "#######################################################################\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "dt_train, dt_test, y_train, y_test = train_test_split(dt_df, y, random_state=42)\n",
    "svc_train, svc_test, y_train, y_test = train_test_split(svc_df, y, random_state=42)\n",
    "rf_train, rf_test, y_train, y_test = train_test_split(rf_df, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "#40     Scale                                       #\n",
    "#   - create standard scaler data for dt and svc.   #\n",
    "#####################################################\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "dt_scaler = StandardScaler().fit(dt_train)\n",
    "dt_train_scaled = dt_scaler.transform(dt_train)\n",
    "dt_test_scaled = dt_scaler.transform(dt_test)\n",
    "\n",
    "svc_scaler = StandardScaler().fit(svc_train)\n",
    "svc_train_scaled = svc_scaler.transform(svc_train)\n",
    "svc_test_scaled = svc_scaler.transform(svc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0.991955756661639, test: 0.9856711915535445, avg 0.9888134741075918\n"
     ]
    }
   ],
   "source": [
    "#################################\n",
    "#50    DecisionTree             #\n",
    "#   a- create and fit model.    #\n",
    "#   b- print score for model.   #\n",
    "#################################\n",
    "\n",
    "#a \n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(ccp_alpha = 0.01, max_features = None, splitter = 'random')\n",
    "clf = clf.fit(dt_train_scaled, y_train)\n",
    "\n",
    "#b\n",
    "train = clf.score(dt_train_scaled, y_train)\n",
    "test = clf.score(dt_test_scaled, y_test)\n",
    "avg = (train+test)/2\n",
    "print (f\"train:  {train}, test: {test}, avg {avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  1.0, test: 0.9879336349924586, avg 0.9939668174962293\n"
     ]
    }
   ],
   "source": [
    "#################################\n",
    "#60    RandomForest             #\n",
    "#   a- create and fit model.    #\n",
    "#   b- print score for model.   #\n",
    "#################################\n",
    "\n",
    "#a \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(ccp_alpha = 0, max_features = None, n_estimators = 500, random_state = None)\n",
    "rf = rf.fit(rf_train, y_train)\n",
    "\n",
    "#b\n",
    "train = rf.score(rf_train, y_train)\n",
    "test = rf.score(rf_test, y_test)\n",
    "avg = (train+test)/2\n",
    "print (f\"train:  {train}, test: {test}, avg {avg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0.9924585218702866, test: 0.9856711915535445, avg 0.9890648567119156\n"
     ]
    }
   ],
   "source": [
    "#################################\n",
    "#70    SVC                      #\n",
    "#   a- create and fit model.    #\n",
    "#   b- print score for model.   #\n",
    "#################################\n",
    "\n",
    "#a \n",
    "from sklearn.svm import SVC \n",
    "model = SVC(C = 5, gamma = 0.0001, kernel = 'linear')\n",
    "model.fit(svc_train_scaled, y_train)\n",
    "\n",
    "#b\n",
    "train = model.score(svc_train_scaled, y_train)\n",
    "test = model.score(svc_test_scaled, y_test)\n",
    "avg = (train+test)/2\n",
    "print (f\"train:  {train}, test: {test}, avg {avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "#150    DecisionTree vs Candidates                               #\n",
    "#   a- scale unknown data and run model against it.              #\n",
    "#   b- predict disposition and add column to df, write to csv.   #\n",
    "##################################################################\n",
    "\n",
    "#a\n",
    "X_dt = unknown_df.drop(\"koi_disposition\", axis=1)\n",
    "\n",
    "cols = [39,33,32,31,30,36,27,25,22,34,16,17,35,10,9]\n",
    "X_dt = X_dt.drop(X_dt.columns[cols],axis=1)\n",
    "\n",
    "X_dt_scaler = StandardScaler().fit(X_dt)\n",
    "X_dt_scaled = X_dt_scaler.transform(X_dt)\n",
    "\n",
    "#b\n",
    "predictions_dt = clf.predict(X_dt_scaled)\n",
    "X_dt[\"koi_predicted\"] = clf.predict(X_dt_scaled)\n",
    "X_dt.to_csv(\"../data_out/dt.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "#160    RandomForest vs Candidates                               #\n",
    "#   a- run model against unknown data.                           #\n",
    "#   b- predict disposition and add column to df, write to csv.   #\n",
    "##################################################################\n",
    "\n",
    "#a\n",
    "X_rf = unknown_df.drop(\"koi_disposition\", axis=1)\n",
    "\n",
    "cols = [27,38,12,28,32,36,37,39,31,11,34,7,13,17,5]\n",
    "X_rf = X_rf.drop(X_rf.columns[cols],axis=1)\n",
    "\n",
    "#b\n",
    "predictions_rf = rf.predict(X_rf)\n",
    "X_rf[\"koi_predicted\"] = rf.predict(X_rf)\n",
    "X_rf.to_csv(\"../data_out/rf.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "#150    SVC vs Candidates                                        #\n",
    "#   a- scale unknown data and run model against it.              #\n",
    "#   b- predict disposition and add column to df, write to csv.   #\n",
    "##################################################################\n",
    "\n",
    "#a\n",
    "X_svc = unknown_df.drop(\"koi_disposition\", axis=1)\n",
    "\n",
    "cols = [12,20,7,9,29,5,23,8,31,27,13,21,37]\n",
    "X_svc = X_svc.drop(X_svc.columns[cols],axis=1)\n",
    "\n",
    "X_svc_scaler = StandardScaler().fit(X_svc)\n",
    "X_svc_scaled = X_svc_scaler.transform(X_svc)\n",
    "\n",
    "#b\n",
    "predictions_svc = model.predict(X_svc_scaled)\n",
    "X_svc[\"koi_predicted\"] = model.predict(X_svc_scaled)\n",
    "X_svc.to_csv(\"../data_out/svc.csv\", index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
